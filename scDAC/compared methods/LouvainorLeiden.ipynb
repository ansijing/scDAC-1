{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from os.path import join as pj \n",
    "import math\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch import nn, autograd \n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from modules import models, utils\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import metrics\n",
    "from numpy import *\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_z_pca = './data/z1/pca_x1.csv'\n",
    "path_label = './data/z1/label_seurat/label.csv'\n",
    "adatapca = sc.read(file_z_pca)\n",
    "sc.pp.normalize_total(adatapca, target_sum=1e4)\n",
    "sc.pp.neighbors(adatapca, n_neighbors=30,n_pcs = 32)\n",
    "\n",
    "results = {}\n",
    "weightrange = arange(0.01, 5, 1)\n",
    "# for cn_components in np.array([12,14,16, 17, 18]):\n",
    "for n_neighbor in np.array([15, 30, 50, 100]):\n",
    "    for n_pc in np.array([5, 10,15,20,25,30,32]):\n",
    "        for resolutions in np.array([0.01,0.1,1,10,100]):\n",
    "        # print('%s-%s'%(cn_components, cweight_concentration_prior))\n",
    "            sc.pp.neighbors(adatapca, n_neighbors=n_neighbor,n_pcs = n_pc)\n",
    "            sc.tl.louvain(adatapca,resolution=resolutions)\n",
    "            label_p = adatapca.obs['louvain']\n",
    "            label_p.to_csv('./data/z1/label_louvain.csv')\n",
    "            sc.tl.leiden(adatapca, resolution=resolutions)\n",
    "            label_ppcalei = adatapca.obs['leiden']\n",
    "            label_ppcalei.to_csv('./data/z1/label_leiden.csv')\n",
    "            path_label2 = './data/z1/label_louvain.csv'\n",
    "            path_label3 = './data/z1/label_leiden.csv'\n",
    "            label = utils.load_csv(path_label)\n",
    "            label_tlist = utils.transpose_list(label)[1][1:]\n",
    "            # label_true = np.array(label_tlist)\n",
    "            label_predictlo = utils.load_csv(path_label2)\n",
    "            label_plistlo = utils.transpose_list(label_predictlo)[1][1:]\n",
    "            label_predictle = utils.load_csv(path_label3)\n",
    "            label_plistle = utils.transpose_list(label_predictle)[1][1:]\n",
    "            # label_plist = utils.transpose_list(label_pre_ten)[0]\n",
    "            z_list = utils.load_csv(file_z_pca)\n",
    "            z_np = np.array(z_list, dtype=np.float64)\n",
    "            arilo = adjusted_rand_score(label_tlist, label_plistlo) #l1 kpca20\n",
    "            # print(\"arilo:\", arilo) \n",
    "            nmilo = normalized_mutual_info_score(label_tlist, label_plistlo)\n",
    "            # print(\"nmilo:\", nmilo)\n",
    "            sclo = silhouette_score(z_np, label_plistlo)\n",
    "            # print(\"sclo\", sclo) \n",
    "            arile = adjusted_rand_score(label_tlist, label_plistle) #l1 kpca20\n",
    "            # print(\"arile:\", arile) \n",
    "            nmile = normalized_mutual_info_score(label_tlist, label_plistle)\n",
    "            # print(\"nmile:\", nmile)\n",
    "            scle = silhouette_score(z_np, label_plistle)\n",
    "            # print(\"scle\", scle) \n",
    "            print(\"n_neighbor\", n_neighbor,\"n_pc\",n_pc,  \"resolution\",resolutions,\"arilo:\", arilo, \"nmilo:\", nmilo, \"sclo\", sclo,\"arile:\", arile,\"nmile:\", nmile,\"scle\", scle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
